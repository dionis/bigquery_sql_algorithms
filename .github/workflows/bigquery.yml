name: "BigQuery CD"
run-name: "BigQuery Continue Deployment"
on:
  workflow_dispatch:
    inputs:
      cloud:
        description: "Proveedor Cloud"
        required: true
        default: "Big-Query"
        options: [ "GCP", "Big-Query"]
jobs:
  big-query:
   runs-on: ubuntu-latest
   permissions:
     contents: 'read'
     id-token: 'write'
   if: github.event.inputs.cloud == 'Big-Query'
   env:
      PROJECT_ID: ${{ vars.GCP_PROJECT_ID }}
      WORLOAD_IDENTITY_PROVIDER: ${{ vars.GCP_WORLOAD_IDENTITY_PROVIDER }}
      SERVICE_NAME: ${{ vars.GCP_SERVICE_NAME }}
      REGION: ${{ vars.GCP_REGION }}
      BIGQUERY_DATASET_REPOSITORY: 'algorithms'
      CREDENTIALS_JSON: ${{secrets.GCP_CREDENTIALS_JSON}}
      gcp_project: env.PROJECT_ID
      dataset_schema_directory: env.BIGQUERY_DATASET_REPOSITORY
      credentials: ${{ secrets.GCP_SA_KEY }}
   steps: 
     - name: Download Google Cloud version
       run: pip install google-cloud-bigquery==2.31.0 
     - name: Checkout
       uses: actions/checkout@v2.3.4
     - name: 'Update algorithms'
       run: echo 'Update algorithms in BigQuery'
     - name: "Autenticar en GCP"
       id: auth
       uses: google-github-actions/auth@ef5d53e30bbcd8d0836f4288f5e50ff3e086997d #v1.0.0
       with:
          credentials_json: ${{ env.CREDENTIALS_JSON }}         
     - name: "Authenticate to GCP "
       run: echo "Token  ${{ steps.auth.outputs.access_token }}"
     - name: "Update BigQuery with use python code"       
       run: cd bigquery_update_process
     - name: "Create environement"
       run: |
          python3 -m venv env
          source env/bin/activate
          pip install -r requirements.txt
     - name: "Deploy to BigQuery"
       run: python  __init__.py
         
    #  - name: Google Bigquery "Deploy table, view and other structure definitions" Action for Github Action
    #    # You may pin to the exact commit or the version.
    #    uses: jashparekh/bigquery-action@0f6660576ba2a5246574edf336ab17fc011af9ec
    #    #uses:  jashparekh/bigquery-action@v3
    #    with:
    #       # Name of the GCP Project
    #       gcp_project: env.PROJECT_ID
    #       # Path to the directory with schemas. Name of the directory should match with the dataset name in BigQuery
    #       dataset_schema_directory: env.BIGQUERY_DATASET_REPOSITORY
    #       # Service account to autheticate with BigQuery
    #       credentials: ${{ secrets.GCP_SA_KEY }}
