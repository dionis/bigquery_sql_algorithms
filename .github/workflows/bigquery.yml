name: "BigQuery CD"
run-name: "BigQuery Continue Deployment"
on:
  workflow_dispatch:
    inputs:
      cloud:
        description: "Proveedor Cloud"
        required: true
        default: "Big-Query"
        options: [ "GCP", "Big-Query"]
jobs:
  big-query:
   runs-on: ubuntu-latest
   permissions:
     contents: 'read'
     id-token: 'write'
   if: github.event.inputs.cloud == 'Big-Query'
   env:
      PROJECT_ID: ${{ vars.GCP_PROJECT_ID }}
      WORLOAD_IDENTITY_PROVIDER: ${{ vars.GCP_WORLOAD_IDENTITY_PROVIDER }}
      SERVICE_NAME: ${{ vars.GCP_SERVICE_NAME }}
      REGION: ${{ vars.GCP_REGION }}
      BIGQUERY_DATASET_REPOSITORY: '../import_dev'
      CREDENTIALS_JSON: ${{secrets.GCP_CREDENTIALS_JSON}}
      gcp_project: ${{ vars.GCP_PROJECT_ID }}
      dataset_schema_directory: '../import_dev'
      credentials: ${{ secrets.GCP_CREDENTIALS_JSON }}
   steps: 
     - name: Download Google Cloud version
       run: pip install google-cloud-bigquery==2.31.0 
     - name: Checkout
       uses: actions/checkout@v2.3.4
     - name: 'Update algorithms'
       run: echo 'Update algorithms in BigQuery'
     - name: "Autenticar en GCP"
       id: auth
       uses: google-github-actions/auth@ef5d53e30bbcd8d0836f4288f5e50ff3e086997d #v1.0.0
       with:
          credentials_json: ${{ env.CREDENTIALS_JSON }}         
     - name: "Authenticate to GCP "
       run: echo "Token  ${{ steps.auth.outputs.access_token }}"

     - name: "Create python enviromenent" 
       run: |
     - uses: actions/setup-python@v5
       with:
          python-version: '3.10'          
     - name: "Move to python script directory"
       working-directory: ./bigquery_update_process
       run: ls -l
     - name: "Execute python requirements.txt file"
       working-directory: ./bigquery_update_process
       run: pip install -r requirements.txt
    #  - name: "Deploy with python file __init__"
    #    working-directory: ./bigquery_update_process       
    #    run: python __init__.py
    #  - name: "Execute with file execute"
    #    working-directory: ./bigquery_update_process       
    #    run: python execute.py
    #  - name: "CSV import with file execute"
    #    working-directory: ./bigquery_update_process       
    #    run: python csv_import.py
     - name: "Execute Update PORA-Algorithm source code"
       working-directory: ./bigquery_update_process       
       run: python update_algorithm.py
        
    #  - name: Google Bigquery "Deploy table, view and other structure definitions" Action for Github Action
    #    # You may pin to the exact commit or the version.
    #    uses: jashparekh/bigquery-action@0f6660576ba2a5246574edf336ab17fc011af9ec
    #    #uses:  jashparekh/bigquery-action@v3
    #    with:
    #       # Name of the GCP Project
    #       gcp_project: env.PROJECT_ID
    #       # Path to the directory with schemas. Name of the directory should match with the dataset name in BigQuery
    #       dataset_schema_directory: env.BIGQUERY_DATASET_REPOSITORY
    #       # Service account to autheticate with BigQuery
    #       credentials: ${{ secrets.GCP_SA_KEY }}
